"""
Data Loader for FastTracker CSV Output

Loads and processes CSV files generated by FastTracker.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Optional, Tuple
import warnings


class TrackingData:
    """Container for FastTracker tracking data loaded from CSV files."""

    def __init__(self):
        self.frame_data: Optional[pd.DataFrame] = None
        self.evaluation_data: Optional[pd.DataFrame] = None
        self.track_trajectories: Dict[int, pd.DataFrame] = {}
        self.ground_truth_trajectories: Dict[int, pd.DataFrame] = {}
        self.model_probs: Dict[int, pd.DataFrame] = {}
        self.performance_stats: Optional[pd.DataFrame] = None

    def summary(self) -> str:
        """Generate a summary string of loaded data."""
        lines = ["=== FastTracker Data Summary ==="]

        if self.frame_data is not None:
            lines.append(f"Frames loaded: {len(self.frame_data)}")
            lines.append(f"Time range: {self.frame_data['time'].min():.2f}s - {self.frame_data['time'].max():.2f}s")
            lines.append(f"Max tracks: {self.frame_data['num_tracks'].max()}")
            lines.append(f"Max confirmed: {self.frame_data['num_confirmed'].max()}")

        if self.evaluation_data is not None:
            lines.append(f"\nEvaluation metrics available: Yes")
            lines.append(f"Avg position error: {self.evaluation_data['avg_position_error'].mean():.2f}m")
            lines.append(f"Avg OSPA distance: {self.evaluation_data['ospa_distance'].mean():.2f}")

        if self.track_trajectories:
            lines.append(f"\nIndividual tracks loaded: {len(self.track_trajectories)}")

        if self.ground_truth_trajectories:
            lines.append(f"Ground truth trajectories loaded: {len(self.ground_truth_trajectories)}")

        return "\n".join(lines)


class CSVDataLoader:
    """Loads FastTracker CSV output files."""

    def __init__(self, base_path: str = "."):
        """
        Initialize the data loader.

        Args:
            base_path: Base directory containing CSV files
        """
        self.base_path = Path(base_path)

    def load_results(self, filename: str = "results.csv") -> pd.DataFrame:
        """
        Load the main results CSV file.

        Args:
            filename: Name of results file

        Returns:
            DataFrame with columns: frame, time, num_tracks, num_confirmed,
                                   num_measurements, processing_time_ms
        """
        filepath = self.base_path / filename

        if not filepath.exists():
            raise FileNotFoundError(f"Results file not found: {filepath}")

        df = pd.read_csv(filepath)

        # Validate expected columns
        expected_cols = ['frame', 'time', 'num_tracks', 'num_confirmed',
                        'num_measurements', 'processing_time_ms']
        missing_cols = set(expected_cols) - set(df.columns)

        if missing_cols:
            warnings.warn(f"Missing expected columns: {missing_cols}")

        return df

    def load_evaluation(self, filename: str = "evaluation_results.csv") -> pd.DataFrame:
        """
        Load the evaluation results CSV file.

        Args:
            filename: Name of evaluation file

        Returns:
            DataFrame with evaluation metrics
        """
        filepath = self.base_path / filename

        if not filepath.exists():
            warnings.warn(f"Evaluation file not found: {filepath}")
            return None

        df = pd.read_csv(filepath)

        # Rename timestamp to time for consistency
        if 'timestamp' in df.columns:
            df = df.rename(columns={'timestamp': 'time'})

        return df

    def load_track_details(self, filename: str = "track_details.csv") -> Dict[int, pd.DataFrame]:
        """
        Load detailed track information (positions, velocities, states).

        Args:
            filename: Name of track details file

        Returns:
            Dictionary mapping track_id to DataFrame with trajectory data
        """
        filepath = self.base_path / filename

        if not filepath.exists():
            warnings.warn(f"Track details file not found: {filepath}. "
                         "Individual track trajectories will not be available.")
            return {}

        df = pd.read_csv(filepath)

        # Group by track_id
        trajectories = {}
        for track_id, group in df.groupby('track_id'):
            trajectories[track_id] = group.sort_values('time').reset_index(drop=True)

        return trajectories

    def load_ground_truth(self, filename: str = "ground_truth.csv") -> Dict[int, pd.DataFrame]:
        """
        Load ground truth trajectories.

        Args:
            filename: Name of ground truth file

        Returns:
            Dictionary mapping target_id to DataFrame with true trajectory data
        """
        filepath = self.base_path / filename

        if not filepath.exists():
            warnings.warn(f"Ground truth file not found: {filepath}. "
                         "Ground truth trajectories will not be available.")
            return {}

        df = pd.read_csv(filepath)

        # Group by target_id
        trajectories = {}
        for target_id, group in df.groupby('target_id'):
            trajectories[target_id] = group.sort_values('time').reset_index(drop=True)

        return trajectories

    def load_all(self, results_file: str = "results.csv",
                 eval_file: str = "evaluation_results.csv",
                 track_file: str = "track_details.csv",
                 ground_truth_file: str = "ground_truth.csv") -> TrackingData:
        """
        Load all available CSV files.

        Args:
            results_file: Main results filename
            eval_file: Evaluation results filename
            track_file: Track details filename
            ground_truth_file: Ground truth trajectories filename

        Returns:
            TrackingData object with all loaded data
        """
        data = TrackingData()

        # Load main results (required)
        print(f"Loading {results_file}...")
        data.frame_data = self.load_results(results_file)

        # Load evaluation data (optional)
        print(f"Loading {eval_file}...")
        data.evaluation_data = self.load_evaluation(eval_file)

        # Load track details (optional)
        print(f"Loading {track_file}...")
        data.track_trajectories = self.load_track_details(track_file)

        # Load ground truth (optional)
        print(f"Loading {ground_truth_file}...")
        data.ground_truth_trajectories = self.load_ground_truth(ground_truth_file)

        # Compute performance stats
        if data.frame_data is not None:
            data.performance_stats = self._compute_performance_stats(data.frame_data)

        print("\n" + data.summary())

        return data

    def _compute_performance_stats(self, frame_data: pd.DataFrame) -> pd.DataFrame:
        """Compute derived performance statistics."""
        stats = frame_data.copy()

        # Compute FPS if not already present
        if 'fps' not in stats.columns and 'processing_time_ms' in stats.columns:
            stats['fps'] = np.where(stats['processing_time_ms'] > 0,
                                   1000.0 / stats['processing_time_ms'],
                                   0)

        # Compute track confirmation rate
        if 'num_tracks' in stats.columns and 'num_confirmed' in stats.columns:
            stats['confirmation_rate'] = np.where(stats['num_tracks'] > 0,
                                                 stats['num_confirmed'] / stats['num_tracks'],
                                                 0)

        return stats


def main():
    """Test the data loader with sample files."""
    import argparse

    parser = argparse.ArgumentParser(description='Test FastTracker CSV data loader')
    parser.add_argument('--path', type=str, default='.',
                       help='Path to directory containing CSV files')
    parser.add_argument('--results', type=str, default='results.csv',
                       help='Results CSV filename')
    parser.add_argument('--eval', type=str, default='evaluation_results.csv',
                       help='Evaluation CSV filename')
    parser.add_argument('--tracks', type=str, default='track_details.csv',
                       help='Track details CSV filename')

    args = parser.parse_args()

    # Load data
    loader = CSVDataLoader(args.path)
    data = loader.load_all(args.results, args.eval, args.tracks)

    # Display basic statistics
    print("\n=== Data Statistics ===")
    if data.frame_data is not None:
        print("\nFrame Data:")
        print(data.frame_data.describe())

    if data.evaluation_data is not None:
        print("\nEvaluation Data:")
        print(data.evaluation_data.describe())


if __name__ == '__main__':
    main()
